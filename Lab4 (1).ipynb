{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17dbc6de-ccf9-48b3-8e4c-688b324d6deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lab4.ipynb', '.ipynb_checkpoints', 'UNITENReview.csv', 'Review.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "036d1240-16d8-4174-b903-6e7388d905c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           Review\n",
      "0   The product arrived on time. Packaging was great, and the quality is amazing!\n",
      "1                                        THIS PRODUCT IS JUST AMAZING! I LOVE IT.\n",
      "2     I bought this phone for $799, and it has a 120Hz display. Totally worth it!\n",
      "3                         Wow!!! This product is awesome... but a bit expensive??\n",
      "4                                             The laptop works perfectly fine.   \n",
      "5    Check out the full product details here: https://example.com/product-details\n",
      "6         <div><h2>Great Purchase!</h2><p>I am happy with this product.</p></div>\n",
      "7                The battry life is excelent, but the chargin cable is too short.\n",
      "8                       I can't believe it's so good! Didn't expect such quality.\n",
      "9                   Love this product! ???? Fast delivery ??, amazing quality! ??\n",
      "10                       TBH, I wasnt expecting much, but OMG, this is awesome!!\n",
      "11                          This is the best product I have ever used in my life!\n",
      "12  The shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "import pandas as pd\n",
    "file_path = \"Review.csv\"\n",
    "df = pd.read_csv(file_path, encoding=\"latin1\")\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e7249e0-5bb8-4aba-94cc-45385c59480d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time. packaging was great, and the quality is amazing!\n",
      "1                                          this product is just amazing! i love it.\n",
      "2       i bought this phone for $799, and it has a 120hz display. totally worth it!\n",
      "3                           wow!!! this product is awesome... but a bit expensive??\n",
      "4                                               the laptop works perfectly fine.   \n",
      "5      check out the full product details here: https://example.com/product-details\n",
      "6           <div><h2>great purchase!</h2><p>i am happy with this product.</p></div>\n",
      "7                  the battry life is excelent, but the chargin cable is too short.\n",
      "8                         i can't believe it's so good! didn't expect such quality.\n",
      "9                     love this product! ???? fast delivery ??, amazing quality! ??\n",
      "10                         tbh, i wasnt expecting much, but omg, this is awesome!!\n",
      "11                            this is the best product i have ever used in my life!\n",
      "12    the shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n",
      "Name: lowercased, dtype: object\n",
      "0     the product arrived on time. packaging was great, and the quality is amazing!\n",
      "1                                          this product is just amazing! i love it.\n",
      "2       i bought this phone for $799, and it has a 120hz display. totally worth it!\n",
      "3                           wow!!! this product is awesome... but a bit expensive??\n",
      "4                                               the laptop works perfectly fine.   \n",
      "5                                         check out the full product details here: \n",
      "6           <div><h2>great purchase!</h2><p>i am happy with this product.</p></div>\n",
      "7                  the battry life is excelent, but the chargin cable is too short.\n",
      "8                         i can't believe it's so good! didn't expect such quality.\n",
      "9                     love this product! ???? fast delivery ??, amazing quality! ??\n",
      "10                         tbh, i wasnt expecting much, but omg, this is awesome!!\n",
      "11                            this is the best product i have ever used in my life!\n",
      "12    the shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n",
      "Name: urls_removed, dtype: object\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /usr/share/pip-wheels\n",
      "Requirement already satisfied: emoji in /home/1913c543-331c-4721-95ae-6d87e099a045/.local/lib/python3.12/site-packages (2.15.0)\n",
      "0     the product arrived on time. packaging was great, and the quality is amazing!\n",
      "1                                          this product is just amazing! i love it.\n",
      "2       i bought this phone for $799, and it has a 120hz display. totally worth it!\n",
      "3                           wow!!! this product is awesome... but a bit expensive??\n",
      "4                                               the laptop works perfectly fine.   \n",
      "5                                         check out the full product details here: \n",
      "6                                      great purchase!i am happy with this product.\n",
      "7                  the battry life is excelent, but the chargin cable is too short.\n",
      "8                         i can't believe it's so good! didn't expect such quality.\n",
      "9                     love this product! ???? fast delivery ??, amazing quality! ??\n",
      "10                         tbh, i wasnt expecting much, but omg, this is awesome!!\n",
      "11                            this is the best product i have ever used in my life!\n",
      "12    the shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n",
      "Name: html_removed, dtype: object\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(df[\u001b[33m\"\u001b[39m\u001b[33mhtml_removed\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Removal of emojis (if any)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01memoji\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# replace emoji with ''\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mremove_emojis\u001b[39m(text):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "# Lowercase conversion\n",
    "def convert_to_lowercase(text):\n",
    " return text.lower()\n",
    "df[\"lowercased\"] = df[\"Review\"].apply(convert_to_lowercase)\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df[\"lowercased\"])\n",
    "\n",
    "# Removal of URLs\n",
    "import re\n",
    "# remove any URLs that start with \"http\" or \"www\" from the text\n",
    "def remove_urls(text):\n",
    " return re.sub(r'http\\S+|www\\S+', '', text)\n",
    "df[\"urls_removed\"] = df[\"lowercased\"].apply(remove_urls)\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df[\"urls_removed\"])\n",
    "\n",
    "!pip install emoji\n",
    "# Removal of HTML tags\n",
    "from bs4 import BeautifulSoup\n",
    "# extracts only the text, removing all HTML tags\n",
    "def remove_html_tags(text):\n",
    " return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "df[\"html_removed\"] = df[\"urls_removed\"].apply(remove_html_tags)\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df[\"html_removed\"])\n",
    "\n",
    "# Removal of emojis (if any)\n",
    "import emoji\n",
    "# replace emoji with ''\n",
    "def remove_emojis(text):\n",
    " return emoji.replace_emoji(text, replace='')\n",
    "df[\"emojis_removed\"] = df[\"html_removed\"].apply(remove_emojis)\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df[\"emojis_removed\"])\n",
    "\n",
    "\n",
    "# Replace Contractions\n",
    "contractions_dict = {\n",
    "    \"wasn't\": \"was not\", \"isn't\": \"is not\", \"aren't\": \"are not\", \"weren't\": \"were not\",\n",
    "    \"doesn't\": \"does not\", \"don't\": \"do not\", \"didn't\": \"did not\", \"can't\": \"cannot\",\n",
    "    \"couldn't\": \"could not\", \"shouldn't\": \"should not\", \"wouldn't\": \"would not\",\n",
    "    \"won't\": \"will not\", \"haven't\": \"have not\", \"hasn't\": \"has not\", \"hadn't\": \"had not\",\n",
    "    \"i'm\": \"i am\", \"you're\": \"you are\", \"he's\": \"he is\", \"she's\": \"she is\",\n",
    "    \"it's\": \"it is\", \"we're\": \"we are\", \"they're\": \"they are\", \"i've\": \"i have\",\n",
    "    \"you've\": \"you have\", \"we've\": \"we have\", \"they've\": \"they have\", \"i'd\": \"i would\",\n",
    "    \"you'd\": \"you would\", \"he'd\": \"he would\", \"she'd\": \"she would\", \"we'd\": \"we would\",\n",
    "    \"they'd\": \"they would\", \"i'll\": \"i will\", \"you'll\": \"you will\", # Fixed syntax error here\n",
    "    \"he'll\": \"he will\", \"she'll\": \"she will\", \"we'll\": \"we will\", \"they'll\": \"they will\",\n",
    "    \"let's\": \"let us\", \"that's\": \"that is\", \"who's\": \"who is\", \"what's\": \"what is\",\n",
    "    \"where's\": \"where is\", \"when's\": \"when is\", \"why's\": \"why is\"\n",
    "}\n",
    "\n",
    "# Build the regex pattern for contractions\n",
    "escaped_contractions = [re.escape(contraction) for contraction in contractions_dict.keys()]\n",
    "joined_contractions = \"|\".join(escaped_contractions)\n",
    "contractions_pattern = r'\\b(' + joined_contractions + r')\\b'\n",
    "compiled_pattern = re.compile(contractions_pattern, flags=re.IGNORECASE)\n",
    "\n",
    "# Define a function to replace contractions\n",
    "def replace_contractions(text):\n",
    "    if pd.isna(text): return \"\"\n",
    "    \n",
    "    # Normalize curly apostrophes (smart quotes) to match dict keys\n",
    "    text = str(text).replace(\"’\", \"'\")\n",
    "    \n",
    "    def replace_match(match):\n",
    "        matched_word = match.group(0).lower() \n",
    "        return contractions_dict[matched_word]\n",
    "    \n",
    "    return compiled_pattern.sub(replace_match, text)\n",
    "\n",
    "# Apply to the column (using 'slangs_replaced' as per your original code)\n",
    "df[\"contractions_replaced\"] = df[\"slangs_replaced\"].apply(replace_contractions)\n",
    "\n",
    "# --- Display Results ---\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"contractions_replaced\"])\n",
    "\n",
    "# Remove punctuations and special characters\n",
    "import string\n",
    "# Function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    " return text.translate(str.maketrans('', '', string.punctuation))\n",
    "# Apply the function to the column\n",
    "df[\"punctuations_removed\"] = df[\"contractions_replaced\"].apply(remove_punctuation)\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df[\"punctuations_removed\"])\n",
    "\n",
    "# Remove numbers\n",
    "def remove_numbers(text):\n",
    " return re.sub(r'\\d+', '', text) # Removes all numeric characters\n",
    "# Apply the function to the column\n",
    "df[\"numbers_removed\"] = df[\"punctuations_removed\"].apply(remove_numbers)\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df[\"numbers_removed\"])\n",
    "\n",
    "# Correct spelling mistakes\n",
    "from autocorrect import Speller\n",
    "# Initialize spell checker\n",
    "spell = Speller(lang='en')\n",
    "# Function to correct spelling\n",
    "def correct_spelling(text):\n",
    " return spell(text) # Apply correction\n",
    "# Apply the function to the column\n",
    "df[\"spelling_corrected\"] = df[\"numbers_removed\"].apply(correct_spelling)\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df[\"spelling_corrected\"])\n",
    "\n",
    "# Remove stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define stopwords list\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()  # Split text into words\n",
    "    filtered_words = []   # Create an empty list\n",
    "    \n",
    "    for word in words:  # Loop through each word\n",
    "        lower_word = word.lower()  # Convert to lowercase\n",
    "        \n",
    "        if lower_word not in stop_words:  # Check if NOT a stopword\n",
    "            filtered_words.append(word)   # Add to filtered list\n",
    "            \n",
    "    return \" \".join(filtered_words)  # Join back into sentence\n",
    "\n",
    "# Apply the function to the column\n",
    "df[\"stopwords_removed\"] = df[\"spelling_corrected\"].apply(remove_stopwords)\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"stopwords_removed\"])\n",
    "\n",
    "# Stemming - reduces words to their base root by chopping off suffixes\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Function to apply stemming\n",
    "def stem_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    words = text.split()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]  # Apply stemming\n",
    "    return \" \".join(stemmed_words)\n",
    "\n",
    "# Apply the function\n",
    "df[\"stemmed_words\"] = df[\"stopwords_removed\"].apply(stem_text)\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"stemmed_words\"])\n",
    "\n",
    "import nltk\n",
    "# Download the required resources\n",
    "nltk.download('wordnet') # For lemmatization\n",
    "nltk.download('omw-1.4') # WordNet lexical database\n",
    "nltk.download('averaged_perceptron_tagger_eng') # For POS tagging\n",
    "nltk.download('punkt_tab') # For tokenization\n",
    "# Lemmatization - reduces words to their base dictionary form (lemma)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to map NLTK POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):  # Adjective\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):  # Verb\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):  # Noun\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):  # Adverb\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to noun\n",
    "\n",
    "# Function to lemmatize text with POS tagging\n",
    "def lemmatize_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "    pos_tags = pos_tag(words)\n",
    "\n",
    "    # Lemmatize each word with its correct POS tag\n",
    "    lemmatized_words = [\n",
    "        lemmatizer.lemmatize(word, get_wordnet_pos(tag))\n",
    "        for word, tag in pos_tags\n",
    "    ]\n",
    "\n",
    "    return \" \".join(lemmatized_words)\n",
    "\n",
    "# Apply the function\n",
    "df[\"lemmatized\"] = df[\"stopwords_removed\"].apply(lemmatize_text)\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"lemmatized\"])\n",
    "\n",
    "df.to_csv(\"Processed_Reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffe27b8f-bc03-4b10-b0bd-c332087cd92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Processed_Reviews.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2025.12-py312",
   "language": "python",
   "name": "conda-env-anaconda-2025.12-py312-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
